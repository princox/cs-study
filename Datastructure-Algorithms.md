##자료구조
자료구조: 주 기억장치에서 데이터를 어떤 구조로 저장하고 탐색해야 가장 효율적인가?  

- 생김새에 따라서 
	- 원시구조
		- 정수, 실수, 문자
	- 선형구조
		- 배열, 연결 리스트, 스택, 큐, 덱
	- 비선형구조
	 	- 트리, 그래프
- 실체화에 따라서 
	- 물리적구조
		- 정수, 실수, 문자
		- 배열, 연결리스트
	- 추상적 구조
		- 스택, 큐, 덱, 트리, 그래프

__자료구조의 구성__

- Access  
- Insert  
- Delegation  
- Searching  
- Copying  
- Sorting  
- Merging  
- Splitting  

__배열__  
같은 데이터 타입을 갖는 둘 이상의 여러 데이터 항목들이 그룹적으로 모여 변수 이름으로 인덱스에 의해 호출되는 자료구조
크기가 가변적이지 않기 떄문에 추가하거나 삭제할 수 없다.  
쉽게 원하는 자료를 찾을 수 있다.

__연결리스트__  
배열에 비해 공간을 많이 차지한다.(다음 데이터의 주소값도 가지고 있기 때문)  
삽입과 삭제가 자유롭게 일어난다.  
자료 탐색 시간이 오래걸린다.(데이터 주소값을 계속 타고 넘어가야함)    
- 요즘은 컴퓨터 성능이 좋아져서 단점이 극복됨. 특정 상황 이외에는 리스트를 많이 사용함

__스택__  
자료의 삽입과 삭제가 한쪽 끝에서만 일어나는 자료구조이다.
나중에 들어온 게 먼저 나감.
삽입과 삭제는 push와 pop연산을 통해 행할 수 있다.  
(접시를 쌓았을 때 맨 위의 접시를 먼저 꺼낸다. / 뒤로가기 버튼)

__큐__  
큐 리스트의 한쪽 끝에서 새로운 자료들이 삽입되고, 다른 반대편 끝에서는 가장 먼저 삽입 되었던 자료들이 삭제되는 구조이다.
삽입과 삭제는 put과 get연산을 통해 행할 수 있다.
(표를 사러온사람들 줄을 섰을 때 먼저온 사람들이 표를 먼저 산다,)

__덱__  
Double ended queue
스택과 큐를 섞음 
(많이 볼일은 없을 것임)

__트리(tree)__  
탐색에 용이하다.
트리에서 자료를 탐색하는 방법도 여러가지가 있다.

__그래프(graph)__  
-facebook graph


__OVERFLOW__  
자료를 삽입하고자 할 때, 꽉 차서 저장될 장소가 없는 경우


__UNDERFLOW__  
자료를 삭제하고자 할 때, 아무것도 삭제할 것이 없는 경우


##알고리즘
- 알고리즘
	- 문제해결을 위한 절차/방법
	- 어떠한 문제를 해결하기 위한 여러 동작들의 모음
	- 대표적 알고리즘 : 정렬, 탐색, 재귀 등

__Selection Sort(선택정렬)__ 
전체 데이터를 보면서 가장 작은 값을 찾아 맨 앞으로 보내는 것을 반복.

__Bubble Sort(버블정렬)__  
첫번째 값과 다음 값을 비교, 더 큰 값이 오른쪽으로 자리를 바꾼다. :마지막수 까지 비교를 반복하면 순차적으로 정렬이 된다.

__Insert Sort(삽입정렬)__  
앞과 뒤를 비교해 사이값으로 들어갈 수 있으면 그 자리에 삽입하는 것을 반복한다.

__Merge Sort(병합정렬)__   
영역을 나누어 각각 비교 정렬하고 그 나뉜 영역을 다시 비교해서 정렬한다.

__Quick Sort(퀵정렬)__  
어떤 상황에서도 평균적으로 가장 빠름 - 평타는 친다

__재귀함수__  
함수 내에서 자기 자신을 다시 호출하는 함수를 말한다.
무한 반복이 되기때문에 탈출조건을 꼭 설정해야한다.
ex) 팩토리얼 / 하노이 타워 / 피보나치 / 버블정렬


__`시간복잡도 Big O`__  
알고리즘이 실행되는데 소요되는 시간분석
점근표기법(대문자 O표기법)
Bic O = 데이터 개수에 따른 비교 연산의 횟수

O(n) : 리스트의 경우 데이터 하나를 찾을 경우.
O(n^2) : 데이터 개수에 따라 기하급수적으로 늘어남
O(로그2 n)

ex)버블정렬의 경우 데이터가 n개일 때
비교 연산의 횟수 =  1 + 2 + … + n-1 
(n: 항의 개수/ a:첫째 항 / l: 마지막 항)
n(a+l) / 2 = ((n-1) * (1+n-1))/2 = (n-1 + 1 + 2n + n^2) / 2
빅오 계산시에는 계수, 상수 다 떼고 가장 큰 수만 남긴다.
O(n^2) -> 데이터가 많아질 수록 기하급수적


